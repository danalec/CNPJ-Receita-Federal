import logging
import time

from src.extract_files import run_extraction
from src.consolidate_csv import run_consolidation
from src.database_loader import run_loader
from src.config import setup_logging

setup_logging()
logger = logging.getLogger(__name__)


def main_pipeline():
    """
    Executa o pipeline de ETL completo, passo a passo.
    """
    logging.info("==================================================")
    logging.info("üöÄ INICIANDO PIPELINE DE DADOS COMPLETO üöÄ")
    logging.info("==================================================")

    start_time = time.time()

    try:
        # --- ETAPA 1: EXTRA√á√ÉO ---
        logging.info("--- [ETAPA 1 de 3] Iniciando extra√ß√£o dos arquivos .zip ---")
        run_extraction()
        logging.info("--- [ETAPA 1 de 3] Extra√ß√£o conclu√≠da com sucesso! ---")

        # --- ETAPA 2: CONSOLIDA√á√ÉO ---
        logging.info("--- [ETAPA 2 de 3] Iniciando consolida√ß√£o dos arquivos .csv ---")
        run_consolidation()
        logging.info("--- [ETAPA 2 de 3] Consolida√ß√£o conclu√≠da com sucesso! ---")

        # --- ETAPA 3: CARGA NO BANCO DE DADOS ---
        logging.info(
            "--- [ETAPA 3 de 3] Iniciando carga de dados para o banco de dados ---"
        )
        run_loader()
        logging.info("--- [ETAPA 3 de 3] Carga de dados conclu√≠da com sucesso! ---")

    except Exception as e:
        logging.error(f"‚ùå O PIPELINE FALHOU. Erro: {e}", exc_info=True)
        return

    end_time = time.time()
    total_time = end_time - start_time
    logging.info("==================================================")
    logging.info(f"‚úÖ PIPELINE DE DADOS FINALIZADO COM SUCESSO! ‚úÖ")
    logging.info(f"‚è±Ô∏è Tempo total de execu√ß√£o: {total_time:.2f} segundos.")
    logging.info("==================================================")


if __name__ == "__main__":
    main_pipeline()
